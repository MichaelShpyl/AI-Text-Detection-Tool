{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotly Dash Dashboard\n",
    "\n",
    "This dashboard allows interactive exploration of the AI Text Detector results. It has three tabs for:\n",
    "1. **EDA** – Visualizing data distributions (class balance, article length, etc.).\n",
    "2. **Evaluation** – Showing model performance metrics (confusion matrix, ROC curves).\n",
    "3. **Inference** – Providing an interface to input new text and get predictions with explanations.\n",
    "\n",
    "Run this app to launch the dashboard locally and interact with the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "from dash import dcc, html\n",
    "import base64, logging\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import logging\n",
    "from utils import dashboard_utils  # for LIME explanations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Image not found, skipping: C:\\Testing\\Final_Year_Project\\AI-Text-Detection-Tool\\diagrams\\confusion_matrix.png\n",
      "WARNING:root:Image not found, skipping: C:\\Testing\\Final_Year_Project\\AI-Text-Detection-Tool\\diagrams\\roc_curves.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize Dash app\n",
    "app = dash.Dash(__name__)\n",
    "app.title = \"AI Text Detector Dashboard\"\n",
    "\n",
    "# ——— 1) Auto‑locate your diagrams/ directory ————————————————\n",
    "def find_diagrams_dir(start: Path = Path.cwd(), marker: str = \"diagrams\") -> Optional[Path]:\n",
    "    \"\"\"\n",
    "    Walk upward from `start` through its parents until you find a folder named `marker`.\n",
    "    Return the Path to that folder, or None if not found.\n",
    "    \"\"\"\n",
    "    for folder in (start, *start.parents):\n",
    "        candidate = folder / marker\n",
    "        if candidate.is_dir():\n",
    "            return candidate\n",
    "    logging.warning(f\"Couldn’t locate a '{marker}/' directory under {start}\")\n",
    "    return None\n",
    "\n",
    "DIAGRAMS_DIR = find_diagrams_dir()\n",
    "\n",
    "# ——— 2) Helper to read & encode image files as base64 URIs, safely ——————\n",
    "def encode_image(filename: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Given a filename (e.g. \"class_distribution.png\"), look in DIAGRAMS_DIR,\n",
    "    read it if present, and return a data URI. If missing, log & return None.\n",
    "    \"\"\"\n",
    "    if DIAGRAMS_DIR is None:\n",
    "        return None\n",
    "\n",
    "    img_path = (DIAGRAMS_DIR / filename).resolve()\n",
    "    if not img_path.exists():\n",
    "        logging.warning(f\"Image not found, skipping: {img_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        raw = img_path.read_bytes()\n",
    "        b64 = base64.b64encode(raw).decode(\"utf-8\")\n",
    "        return f\"data:image/png;base64,{b64}\"\n",
    "    except Exception as e:\n",
    "        logging.warning(f\"Failed to encode {img_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# ——— 3) Load pre‑generated plots (won’t crash if missing) ————————\n",
    "class_dist_img  = encode_image(\"class_distribution.png\")\n",
    "length_dist_img = encode_image(\"length_distribution.png\")\n",
    "conf_matrix_img = encode_image(\"confusion_matrix.png\")\n",
    "roc_curves_img  = encode_image(\"roc_curves.png\")\n",
    "\n",
    "# ——— 4) Define app layout ————————————————————————————————\n",
    "app.layout = html.Div([\n",
    "    html.H1(\n",
    "        \"AI‑Generated Text Detection Dashboard\",\n",
    "        style={\"textAlign\": \"center\", \"marginBottom\": \"1em\"}\n",
    "    ),\n",
    "    dcc.Tabs(id=\"tabs\", value=\"tab-eda\", children=[\n",
    "        dcc.Tab(label=\"EDA\",        value=\"tab-eda\"),\n",
    "        dcc.Tab(label=\"Evaluation\", value=\"tab-eval\"),\n",
    "        dcc.Tab(label=\"Inference\",  value=\"tab-inf\"),\n",
    "    ]),\n",
    "    html.Div(id=\"tab-content\")\n",
    "])\n",
    "\n",
    "# (Callbacks will go here in later cells…)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model & tokenizer once\n",
    "model_path = \"diagrams/final_model\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()\n",
    "\n",
    "# Class names in the correct order\n",
    "label_names = [\"Human-written\", \"AI-paraphrased\", \"AI-generated\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash.dependencies import Input, Output\n",
    "\n",
    "@app.callback(Output(\"tab-content\", \"children\"), Input(\"tabs\", \"value\"))\n",
    "def render_tab_content(tab):\n",
    "    if tab == \"tab-eda\":\n",
    "        return html.Div([\n",
    "            html.H3(\"Exploratory Data Analysis\", style={\"textAlign\": \"center\", \"marginTop\": \"1em\"}),\n",
    "            html.Img(src=class_dist_img, style={\"width\": \"45%\", \"display\": \"inline-block\", \"padding\": \"1em\"}),\n",
    "            html.Img(src=length_dist_img, style={\"width\": \"45%\", \"display\": \"inline-block\", \"padding\": \"1em\"}),\n",
    "            html.P(\n",
    "                \"The dataset is fairly balanced across classes. \"\n",
    "                \"Human-written texts are generally longer than AI-generated or AI-paraphrased ones.\",\n",
    "                style={\"textAlign\": \"center\", \"fontStyle\": \"italic\", \"marginTop\": \"0.5em\"}\n",
    "            )\n",
    "        ])\n",
    "    elif tab == \"tab-eval\":\n",
    "        # Evaluation tab: show confusion matrix and ROC curves\n",
    "        return html.Div([\n",
    "            html.H3(\"Model Evaluation\", style={\"textAlign\": \"center\", \"marginTop\": \"1em\"}),\n",
    "            html.Img(src=conf_matrix_img, style={\"width\": \"40%\", \"display\": \"inline-block\", \"padding\": \"1em\"}),\n",
    "            html.Img(src=roc_curves_img, style={\"width\": \"50%\", \"display\": \"inline-block\", \"padding\": \"1em\"}),\n",
    "            html.P(\n",
    "                \"Overall accuracy ~91%. The model excels at identifying human-written text (near 99% recall) \"\n",
    "                \"and mostly confuses paraphrased vs directly AI-generated text.\",\n",
    "                style={\"textAlign\": \"center\", \"fontStyle\": \"italic\", \"marginTop\": \"0.5em\"}\n",
    "            )\n",
    "        ])\n",
    "    elif tab == \"tab-inf\":\n",
    "        # Inference tab: textarea + button + placeholder for results\n",
    "        return html.Div([\n",
    "            html.H3(\"Try the Detector\", style={\"textAlign\": \"center\", \"marginTop\": \"1em\"}),\n",
    "            dcc.Textarea(\n",
    "                id=\"input-text\",\n",
    "                placeholder=\"Enter article text here...\",\n",
    "                style={\"width\": \"80%\", \"height\": \"100px\"}\n",
    "            ),\n",
    "            html.Br(),\n",
    "            html.Button(\"Detect\", id=\"detect-button\", n_clicks=0, style={\"marginTop\": \"0.5em\"}),\n",
    "            html.Div(id=\"result-output\", style={\"marginTop\": \"1em\"})\n",
    "        ])\n",
    "    return html.Div() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash.dependencies import Input, Output\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"result-output\", \"children\"),\n",
    "    [Input(\"detect-button\", \"n_clicks\"), Input(\"input-text\", \"value\")]\n",
    ")\n",
    "def run_detection(n_clicks, input_text):\n",
    "    if not n_clicks or not input_text:\n",
    "        return \"\"\n",
    "    # 1) Tokenize & predict\n",
    "    tokens = tokenizer(\n",
    "        input_text, return_tensors=\"pt\",\n",
    "        truncation=True, padding=True, max_length=512\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        logits = model(**tokens).logits\n",
    "        probs = torch.softmax(logits, dim=1)[0].cpu().numpy()\n",
    "    pred_idx = int(np.argmax(probs))\n",
    "    pred_label = label_names[pred_idx]\n",
    "    confidence = probs[pred_idx]\n",
    "    logging.info(f\"Predicted {pred_label} ({confidence:.3f})\")\n",
    "\n",
    "    # 2) Get LIME explanation (top 6 words)\n",
    "    explanation = dashboard_utils.explain_prediction(\n",
    "        input_text, tokenizer, model, num_features=6\n",
    "    )\n",
    "    # Build a lookup of word→weight\n",
    "    weights = {w.lower(): wt for w, wt in explanation}\n",
    "    max_w = max(abs(wt) for wt in weights.values()) if weights else 1.0\n",
    "\n",
    "    # 3) Render probability bars\n",
    "    prob_rows = []\n",
    "    for i, name in enumerate(label_names):\n",
    "        pct = probs[i] * 100\n",
    "        bar = html.Div(style={\n",
    "            \"width\": f\"{pct}%\", \"height\": \"8px\", \"backgroundColor\": \"#4c8bf5\"\n",
    "        })\n",
    "        prob_rows.append(\n",
    "            html.Div([bar, html.Span(f\" {name}: {pct:.1f}%\")],\n",
    "                     style={\"display\":\"flex\",\"alignItems\":\"center\",\"margin\":\"4px 0\"})\n",
    "        )\n",
    "\n",
    "    # 4) Highlight important words\n",
    "    nodes = []\n",
    "    for word in input_text.split():\n",
    "        key = word.strip(\".,!?;:\").lower()\n",
    "        if key in weights:\n",
    "            w = weights[key]\n",
    "            opacity = min(abs(w)/max_w,1.0)\n",
    "            color = f\"rgba(255,165,0,{opacity:.2f})\"\n",
    "            nodes.append(html.Span(word+\" \",\n",
    "                                   style={\"backgroundColor\": color},\n",
    "                                   title=f\"Weight: {w:+.2f}\"))\n",
    "        else:\n",
    "            nodes.append(html.Span(word+\" \"))\n",
    "\n",
    "    # 5) Compose output\n",
    "    return html.Div([\n",
    "        html.H4(f\"Prediction: {pred_label}\", style={\"textAlign\":\"center\"}),\n",
    "        html.P(f\"Confidence: {confidence*100:.2f}%\", style={\"textAlign\":\"center\"}),\n",
    "        html.Div(prob_rows, style={\"margin\":\"0.5em 0\"}),\n",
    "        html.P(nodes, style={\"lineHeight\":\"1.8em\"})\n",
    "    ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1ad3700e0a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app.run_server(debug=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyProject (Conda)",
   "language": "python",
   "name": "myproject"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
